{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "sun:tf.keras.Input\n",
    "sun:tf.keras.backend\n",
    "sun:tf.reshape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "457d7b5f52198623"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-22T15:56:03.843795400Z",
     "start_time": "2024-05-22T15:56:03.827281300Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cd29a4b16c538b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 对tensor的理解\n",
    "\n",
    "keras.Input(shape=(1,), name='input', dtype=tf.int64) 这行代码表示创建了一个名为 input 的输入层，这个输入层有一个特征，维度为 1 维，数据类型为整数（int64）。\n",
    "尽管维度是1维，但是在 TensorFlow 中，即使是一维的特征也需要被表示为张量，因此在这里使用了 (1,) 表示维度为1\n",
    "shape=(1,) 中的 1 表示这个特征的维度为1，而不是表示这个特征本身是一个向量。在这种情况下，每个样本只包含一个特征值。\n",
    "所以可以想象一个dataframe\n",
    "      特征1\n",
    "样本1   1\n",
    "样本2   2\n",
    "样本3   3\n",
    "...\n",
    "\n",
    "keras.Input(shape=(1,))代表的就是这样的输入层"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "165179fe0b1623f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 所以在定义输入层时，是不知道样本数相关概念的对吧？\n",
    "在定义神经网络模型的输入层时，通常是不需要明确指定样本数量的。输入层的形状（shape）通常用来指定每个样本的特征数量，而样本的数量通常在训练时由输入数据的批次大小（batch size）确定。\n",
    "在训练神经网络时，您会将整个数据集分成批次（batches）来输入模型进行训练。每个批次中包含一定数量的样本，这个数量就是批次大小。因此，样本数量是由数据集中的样本总数和批次大小共同决定的。\n",
    "在定义神经网络模型时，您只需要关注每个样本的特征数量，而不需要显式地指定样本数量。样本数量在训练时会根据批次大小动态确定。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51aa4b428dd8fee5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# shape(x,) 中x代表特征数，这个input代表有一个特征，每个样本只包含一个特征值\n",
    "input = keras.Input(shape=(1,), name='input', dtype=tf.int64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T15:56:03.869735700Z",
     "start_time": "2024-05-22T15:56:03.845906400Z"
    }
   },
   "id": "791b94670992907a",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### keras.Input(shape=(2,))的理解\n",
    "keras.Input(shape=(2,), name='input', dtype=tf.int64) 这行代码表示创建了一个名为 input 的输入层，这个输入层有两个特征，每个特征的维度为 1 维，数据类型为整数（int64）。\n",
    "在这种情况下，每个样本有两个特征，每个特征都是一个单独的维度为1的向量。这种表示方式适用于许多机器学习模型，包括神经网络模型，其中每个样本可以包含多个特征。\n",
    "因此，shape=(2,) 中的 2 表示这个输入层有两个特征，每个特征的维度为1。这种方式适用于表示多特征的情况，每个特征都是一个单独的维度。\n",
    "所以可以想象一个dataframe\n",
    "      特征1  特征2\n",
    "样本1   1      2\n",
    "样本2   2      7\n",
    "样本3   3      8\n",
    "..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bcbc1865f49866"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### feature_column转化特征\n",
    "在使用 keras.Input 定义输入层时，shape 参数中的第一个值表示特征的数量，而每个特征本身是一个一维向量。\n",
    "如果您使用 feature_column 将一个数字特征分桶成了6个桶，那么可以将这个数字特征转化为6个特征来输入模型。每个特征代表一个桶，每个特征是一个一维向量。\n",
    "例如，如果您有一个数字特征被分成了6个桶，您可以将这6个桶作为6个独立的特征输入到模型中，每个特征是一个一维向量，表示该特征的值。这种方式可以帮助模型更好地理解和利用原始数据的特征"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ea159e9da6a3610"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]], shape=(8, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# a特征每个样本是一个数字\n",
    "data = {'a': [15, 9, 17, 19, 21, 18, 25, 30]}\n",
    "a = tf.feature_column.numeric_column('a')\n",
    "a_buckets = tf.feature_column.bucketized_column(a,\n",
    "   boundaries=[10, 15, 20, 25, 30])\n",
    "feature_layer1 = tf.keras.layers.DenseFeatures([a_buckets])\n",
    "## 这里一个特征转化为6个特征\n",
    "print(feature_layer1(data))    ## shape : 8 * 6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T15:56:03.877992500Z",
     "start_time": "2024-05-22T15:56:03.863508100Z"
    }
   },
   "id": "ee6f0a549900cc36",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### tf.tile\n",
    "假设有一个形状为 (2, 2) 的张量 x：\n",
    "     x = tf.constant([[1, 2], [3, 4]])\n",
    "如果我们想要沿着某些维度多次复制这个张量，可以使用 tf.tile：\n",
    "   tf.tile(x, [2, 3])\n",
    "这将会在第一个维度上复制 2 次，在第二个维度上复制 3 次，最终得到一个形状为 (4, 6) 的张量。\n",
    "注意：\n",
    "1.tf.tile 不会改变张量的形状，而是复制数据。\n",
    "2.复制的次数由 multiples 参数决定，这个参数的长度必须和输入张量的维度一致。\n",
    "3.复制的次数可以是任意正整数，包括 0。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e53ebbc29b86773c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3 1 2 3]\n",
      " [4 5 6 4 5 6]], shape=(2, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3],[4,5,6]], tf.int32)\n",
    "b = tf.constant([1,2], tf.int32)\n",
    "# a的形状(2,3) b在第一个维度复制1次，第二个维度复制2次，复制完形状(2,6)\n",
    "print(tf.tile(a, b))  # [[1,2,3,1,2,3],[4,5,6,4,5,6]]\n",
    "c = tf.constant([2,1], tf.int32)\n",
    "\n",
    "# a的形状(2,3) b在第一个维度复制2次，第二个维度复制1次，复制完形状(4,6)\n",
    "print(tf.tile(a, c))  # [[1,2,3], [4,5,6], [1,2,3], [4,5,6]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:00:02.061243600Z",
     "start_time": "2024-05-22T16:00:02.030517800Z"
    }
   },
   "id": "ec68990ca3975f50",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### tensor做运算"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c937428c0ecfb309"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 5 12]\n",
      " [21 32]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[-4 -4]\n",
      " [-4 -4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 定义两个张量\n",
    "tensor1 = tf.constant([[1, 2], \n",
    "                       [3, 4]])\n",
    "tensor2 = tf.constant([[5, 6], \n",
    "                       [7, 8]])\n",
    "\n",
    "\n",
    "# 使用 tf.multiply() 函数进行相乘\n",
    "result1 = tf.multiply(tensor1, tensor2)\n",
    "result2 = tf.subtract(tensor1, tensor2)\n",
    "\n",
    "# 或者直接使用 * 运算符\n",
    "result1 = tensor1 * tensor2\n",
    "result2 = tensor1 - tensor2\n",
    "# 打印结果\n",
    "print(result1)\n",
    "print(result2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:14:18.616288Z",
     "start_time": "2024-05-22T16:14:18.591559900Z"
    }
   },
   "id": "ef6206b85bc1293",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 50, 32)\n",
      "(None, 32)\n",
      "2\n",
      "--------------------------------------\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 32), dtype=tf.float32, name=None), name='tf.reshape_2/Reshape:0', description=\"created by layer 'tf.reshape_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 50, 32), dtype=tf.float32, name=None), name='tf.tile_1/Tile:0', description=\"created by layer 'tf.tile_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 50, 32), dtype=tf.float32, name=None), name='tf.math.subtract_1/Sub:0', description=\"created by layer 'tf.math.subtract_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 50, 32), dtype=tf.float32, name=None), name='tf.math.multiply/Mul:0', description=\"created by layer 'tf.math.multiply'\")\n"
     ]
    }
   ],
   "source": [
    "keys = tf.keras.Input(shape=(50, 32), name='keys')\n",
    "print(keys.shape)\n",
    "input = tf.keras.Input(shape=(32,), name='input')  # (none, 32)\n",
    "input_shape = tf.keras.backend.int_shape(input) # (none, 32)\n",
    "print(input_shape)\n",
    "print(len(input_shape))\n",
    "print('--------------------------------------')\n",
    "## input数据每一个样本: [1, 2, 3, .....]  reshape后每一个样本：1个特征，每个特征32维 [[1,2,3,4,5,6 ...]]\n",
    "input_reshape = tf.reshape(input, shape=[-1, 1, 32])\n",
    "print(input_reshape)   ## (none, 1, 32)\n",
    "\n",
    "input_tile = tf.tile(input_reshape, multiples=[1, 50, 1])\n",
    "print(input_tile)    ## (none, 50, 32)  这个操作在特征上扩展了50倍啊 。变成了从[[1,2,3...],[1,2,3...]....]\n",
    "# 做减法，形状不变\n",
    "print(input_tile - keys) ## (none, 50, 32)\n",
    "print(input_tile * keys) ## (none, 50, 32)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:11:41.652017600Z",
     "start_time": "2024-05-22T16:11:41.629247400Z"
    }
   },
   "id": "2e18bc0ce205c837",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T15:56:03.987294400Z",
     "start_time": "2024-05-22T15:56:03.987294400Z"
    }
   },
   "id": "b7219313a073edf5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
