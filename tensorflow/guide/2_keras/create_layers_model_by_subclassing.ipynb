{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-05-24T15:20:37.661596300Z",
     "start_time": "2024-05-24T15:20:36.421091Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "599302e1b22a6a34",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T15:20:37.675880400Z",
     "start_time": "2024-05-24T15:20:37.662608Z"
    }
   },
   "outputs": [],
   "source": [
    "class Linear(keras.layers.Layer):\n",
    "    def __init__(self, units=32, input_dim=32):\n",
    "        super(Linear, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=b_init(shape=(units,), dtype=\"float32\"), trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5316818f2f796",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 层解读\n",
    "输入2，输出 4\n",
    "其中的一个样本：[x1, x2]\n",
    "\n",
    "层计算的输出过程\n",
    "xw + b = y （这里面 x，w，b，y 都是向量）\n",
    "\n",
    "w11x1 + w21x2 + b1 = y1\n",
    "w12x1 + w22x2 + b2 = y2\n",
    "w13x1 + w23x2 + b3 = y3\n",
    "w14x1 + w24x2 + b4 = y4\n",
    "\n",
    "参数矩阵 2 * 4\n",
    "w = \n",
    "w11  w12  w13  w14\n",
    "w21  w22  w23  w24\n",
    "\n",
    "x = 【x1  x2】\n",
    "\n",
    "样本数是 2，输出是 2 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "226a587bfd441ce4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T15:20:37.707757600Z",
     "start_time": "2024-05-24T15:20:37.676966300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.08111025 -0.101977    0.0048208   0.03084516]\n",
      " [ 0.08111025 -0.101977    0.0048208   0.03084516]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.ones((2, 2))\n",
    "linear_layer = Linear(4, 2)\n",
    "y = linear_layer(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d89c077336759",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 层中可以嵌套，可递归组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e11012defff7ac20",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T15:20:37.735426800Z",
     "start_time": "2024-05-24T15:20:37.708839100Z"
    }
   },
   "outputs": [],
   "source": [
    "## 定义新的线性层\n",
    "class Linear(keras.layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        print('Linear __init__:' + str(units))\n",
    "        super(Linear, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print('Linear build:' + str(input_shape))\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        print('Linear call:' + str(inputs))\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f5b4d4d9af3cbb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T15:20:37.744099300Z",
     "start_time": "2024-05-24T15:20:37.724168500Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPBlock(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        print('MLPBlock __init__')\n",
    "        super(MLPBlock, self).__init__()\n",
    "        self.linear_1 = Linear(32)\n",
    "        self.linear_2 = Linear(32)\n",
    "        self.linear_3 = Linear(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        print('MLPBlock call top: ' + str(inputs.shape))\n",
    "        x = self.linear_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        print('MLPBlock call end: ')\n",
    "        return self.linear_3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162057bafcdf215d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 层的输入的思考\n",
    "输入是 3, 64\n",
    "模型是 64, 32, 32, 1\n",
    "模型相乘：矩阵 (3, 64)与 (64, 32)相乘，结果形状是 3,32\n",
    "思考：\n",
    "   假如输入是(64,), 64个特征，样本数量未知，结果是(32,)也就是最后产生的是：none * 32个数据\n",
    "现在输入是(3, 64), 理解成 3 个特征，每个特征 64位。也可以理解成 3 组的 64个特征。最后产生 none * 3 * 32个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65012c89a023e616",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T15:20:37.815373400Z",
     "start_time": "2024-05-24T15:20:37.738574800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPBlock __init__\n",
      "Linear __init__:32\n",
      "Linear __init__:32\n",
      "Linear __init__:1\n",
      "MLPBlock call top: (3, 64)\n",
      "Linear build:(3, 64)\n",
      "Linear call:Tensor(\"Placeholder:0\", shape=(3, 64), dtype=float32)\n",
      "Linear build:(3, 32)\n",
      "Linear call:Tensor(\"mlp_block/Relu:0\", shape=(3, 32), dtype=float32)\n",
      "MLPBlock call end: (3, 64)\n",
      "Linear build:(3, 32)\n",
      "Linear call:Tensor(\"mlp_block/Relu_1:0\", shape=(3, 32), dtype=float32)\n",
      "MLPBlock call top: (3, 64)\n",
      "Linear call:tf.Tensor(\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]], shape=(3, 64), dtype=float32)\n",
      "Linear call:tf.Tensor(\n",
      "[[0.         0.         0.77229595 0.48545265 0.5747805  0.7942312\n",
      "  0.58506024 0.         0.61449665 0.14962989 0.         0.03993073\n",
      "  0.         0.         0.19993591 0.03521477 1.1768259  0.\n",
      "  0.         0.03818615 0.03078627 0.74797    0.14823282 0.52963626\n",
      "  0.         0.10593382 0.41226152 0.         0.27425802 0.3078016\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.77229595 0.48545265 0.5747805  0.7942312\n",
      "  0.58506024 0.         0.61449665 0.14962989 0.         0.03993073\n",
      "  0.         0.         0.19993591 0.03521477 1.1768259  0.\n",
      "  0.         0.03818615 0.03078627 0.74797    0.14823282 0.52963626\n",
      "  0.         0.10593382 0.41226152 0.         0.27425802 0.3078016\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.77229595 0.48545265 0.5747805  0.7942312\n",
      "  0.58506024 0.         0.61449665 0.14962989 0.         0.03993073\n",
      "  0.         0.         0.19993591 0.03521477 1.1768259  0.\n",
      "  0.         0.03818615 0.03078627 0.74797    0.14823282 0.52963626\n",
      "  0.         0.10593382 0.41226152 0.         0.27425802 0.3078016\n",
      "  0.         0.        ]], shape=(3, 32), dtype=float32)\n",
      "MLPBlock call end: (3, 64)\n",
      "Linear call:tf.Tensor(\n",
      "[[0.         0.1272423  0.27195185 0.         0.         0.\n",
      "  0.01110642 0.08065556 0.10980895 0.11142263 0.         0.04620218\n",
      "  0.         0.02997546 0.         0.         0.02560227 0.01599009\n",
      "  0.         0.         0.05694303 0.         0.00462753 0.\n",
      "  0.         0.         0.13872355 0.06326136 0.         0.07253014\n",
      "  0.         0.        ]\n",
      " [0.         0.1272423  0.27195185 0.         0.         0.\n",
      "  0.01110642 0.08065556 0.10980895 0.11142263 0.         0.04620218\n",
      "  0.         0.02997546 0.         0.         0.02560227 0.01599009\n",
      "  0.         0.         0.05694303 0.         0.00462753 0.\n",
      "  0.         0.         0.13872355 0.06326136 0.         0.07253014\n",
      "  0.         0.        ]\n",
      " [0.         0.1272423  0.27195185 0.         0.         0.\n",
      "  0.01110642 0.08065556 0.10980895 0.11142263 0.         0.04620218\n",
      "  0.         0.02997546 0.         0.         0.02560227 0.01599009\n",
      "  0.         0.         0.05694303 0.         0.00462753 0.\n",
      "  0.         0.         0.13872355 0.06326136 0.         0.07253014\n",
      "  0.         0.        ]], shape=(3, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPBlock()\n",
    "one = tf.ones(shape=(3, 64)) # 3个特征，每个特征是 64位\n",
    "mlp_model = tf.keras.Sequential([mlp])\n",
    "y = mlp_model(one)  # The first call to the `mlp` will create the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58629ba8c0abb764",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T15:20:37.839961400Z",
     "start_time": "2024-05-24T15:20:37.816394900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mlp_block (MLPBlock)         (3, 1)                    3169      \n",
      "=================================================================\n",
      "Total params: 3,169\n",
      "Trainable params: 3,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 这里我们能发现，这个层的接口，中间嵌套了一些 layer，这个 model 是追踪不到的\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54573807512963f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T15:20:37.851287500Z",
     "start_time": "2024-05-24T15:20:37.831794900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_block/linear_1/Variable:0 (64, 32)\n",
      "mlp_block/linear_1/Variable:0 (32,)\n",
      "mlp_block/linear_2/Variable:0 (32, 32)\n",
      "mlp_block/linear_2/Variable:0 (32,)\n",
      "mlp_block/linear_3/Variable:0 (32, 1)\n",
      "mlp_block/linear_3/Variable:0 (1,)\n"
     ]
    }
   ],
   "source": [
    "# 我们看看权重相关细节\n",
    "for weight in mlp.weights:\n",
    "    print(weight.name, weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33951a64a9fcda92",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 对于层次模型的调用顺序\n",
    "1. 首先是mlp = MLPBlock()，需要创建层\n",
    "MLPBlock __init__\n",
    "Linear __init__:32\n",
    "Linear __init__:32\n",
    "Linear __init__:1\n",
    "2. mlp(input)调用层相当于调用__call__方法，其中会访问call方法\n",
    "MLPBlock call top: (None, 64)\n",
    "3. 在真正用到层的时候，才会延迟构造层结构，即调用build()方法，然后调用call方法实现调用，下面是三个linear调用\n",
    "Linear build:(None, 64)\n",
    "Linear call:Tensor(\"Placeholder:0\", shape=(None, 64), dtype=float32)\n",
    "Linear build:(None, 32)\n",
    "Linear call:Tensor(\"mlp_block_1/Relu:0\", shape=(None, 32), dtype=float32)\n",
    "4. 最后一个linear的调用看看在end打印之后\n",
    "MLPBlock call end: (None, 64)\n",
    "Linear build:(None, 32)\n",
    "Linear call:Tensor(\"mlp_block_1/Relu_1:0\", shape=(None, 32), dtype=float32)\n",
    "\n",
    "## tf.one(shape=(3, 64)) 与 tf.keras.Input(shape=(64,)) 与 tf.keras.Input(shape=(3, 64)) 理解\n",
    "输入数据的形状：当你使用 tf.ones(shape=(3, 64)) 创建一个张量时，你得到的是一个形状为 (3, 64) 的张量，这意味着有 3 个样本，每个样本有 64 个特征。这是因为 TensorFlow（和大多数深度学习框架）通常期望数据的第一个维度是批次大小（即样本数量），剩下的维度是特征的维度。\n",
    "tf.keras.Input 的用法：当你定义一个模型输入层 tf.keras.Input((64,)) 时，你告诉框架期望的输入将是一个形状为 (None, 64) 的张量，其中 None 是一个占位符，代表任意大小的批次。这意味着模型期望每个输入样本有 64 个特征，并且可以接受任意数量的样本作为批次输入。\n",
    "特征数量的理解：对于 tf.keras.Input((3,64))，这会创建一个期望输入形状为 (None, 3, 64) 的模型。在这种情况下，你告诉模型每个样本实际上是一个形状为 (3, 64) 的二维数组，这可能代表一个有 3 个时间步长的序列，每个时间步长有 64 个特征，或者是其他类似的数据结构。这并不意味着有 3*64 个不同的特征，而是数据的结构更加复杂，比如时间序列数据、图像数据等。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "897efb487fb36c63",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T15:20:37.871783900Z",
     "start_time": "2024-05-24T15:20:37.846161600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPBlock __init__\n",
      "Linear __init__:32\n",
      "Linear __init__:32\n",
      "Linear __init__:1\n",
      "MLPBlock call top: (None, 64)\n",
      "Linear build:(None, 64)\n",
      "Linear call:Tensor(\"Placeholder:0\", shape=(None, 64), dtype=float32)\n",
      "Linear build:(None, 32)\n",
      "Linear call:Tensor(\"mlp_block_1/Relu:0\", shape=(None, 32), dtype=float32)\n",
      "MLPBlock call end: (None, 64)\n",
      "Linear build:(None, 32)\n",
      "Linear call:Tensor(\"mlp_block_1/Relu_1:0\", shape=(None, 32), dtype=float32)\n",
      "mlp_block_1/linear_4/Variable:0 (64, 32)\n",
      "mlp_block_1/linear_4/Variable:0 (32,)\n",
      "mlp_block_1/linear_5/Variable:0 (32, 32)\n",
      "mlp_block_1/linear_5/Variable:0 (32,)\n",
      "mlp_block_1/linear_6/Variable:0 (32, 1)\n",
      "mlp_block_1/linear_6/Variable:0 (1,)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPBlock()\n",
    "input = tf.keras.Input((64,))\n",
    "mlp(input)\n",
    "for weight in mlp.weights:\n",
    "    print(weight.name, weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1389aa681dc4dc0f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T15:20:37.881061Z",
     "start_time": "2024-05-24T15:20:37.863611200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPBlock __init__\n",
      "Linear __init__:32\n",
      "Linear __init__:32\n",
      "Linear __init__:1\n",
      "MLPBlock call top: (None, 3, 64)\n",
      "Linear build:(None, 3, 64)\n",
      "Linear call:Tensor(\"Placeholder:0\", shape=(None, 3, 64), dtype=float32)\n",
      "Linear build:(None, 3, 32)\n",
      "Linear call:Tensor(\"mlp_block_2/Relu:0\", shape=(None, 3, 32), dtype=float32)\n",
      "MLPBlock call end: (None, 3, 64)\n",
      "Linear build:(None, 3, 32)\n",
      "Linear call:Tensor(\"mlp_block_2/Relu_1:0\", shape=(None, 3, 32), dtype=float32)\n",
      "mlp_block_2/linear_7/Variable:0 (64, 32)\n",
      "mlp_block_2/linear_7/Variable:0 (32,)\n",
      "mlp_block_2/linear_8/Variable:0 (32, 32)\n",
      "mlp_block_2/linear_8/Variable:0 (32,)\n",
      "mlp_block_2/linear_9/Variable:0 (32, 1)\n",
      "mlp_block_2/linear_9/Variable:0 (1,)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPBlock()\n",
    "input = tf.keras.Input((3, 64))\n",
    "mlp(input)\n",
    "for weight in mlp.weights:\n",
    "    print(weight.name, weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bef3cc149bdcc7c",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
