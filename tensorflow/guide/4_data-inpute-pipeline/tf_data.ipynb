{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-07T23:39:33.759686100Z",
     "start_time": "2024-05-07T23:39:32.561436800Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.data\n",
    "\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 3.]\n",
      " [3. 7.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.tensor, TF中基本都是张量在进行流转\n",
    "# Compute some values using a Tensor\n",
    "c = tf.constant([[1.0, 2.0],\n",
    "                 [3.0, 4.0]])\n",
    "d = tf.constant([[1.0, 1.0],\n",
    "                 [0.0, 1.0]])\n",
    "e = tf.matmul(c, d)\n",
    "print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T23:39:33.804945200Z",
     "start_time": "2024-05-07T23:39:33.762775700Z"
    }
   },
   "id": "da0a5f60680b020f",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## #tf.data.dataset.from_tensor_slices\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2d1455c69d659a1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1, 2]), array([3, 4])]\n",
      "[(1, 3, 5), (2, 4, 6)]\n",
      "[array([1, 2]), array([3, 4]), array([5, 6])]\n",
      "[{'a': 1, 'b': 3}, {'a': 2, 'b': 4}]\n",
      "[({'a': 1, 'b': 3}, {'c': 5}), ({'a': 2, 'b': 4}, {'c': 6})]\n",
      "[({'a': {'aa': 1}, 'b': {'bb': 3}}, {'c': {'cc': 5}}), ({'a': {'aa': 2}, 'b': {'bb': 4}}, {'c': {'cc': 6}})]\n",
      "(array([[1, 3],\n",
      "       [2, 3]]), array([[b'A'],\n",
      "       [b'A']], dtype=object))\n",
      "(array([[2, 1],\n",
      "       [1, 2]]), array([[b'B'],\n",
      "       [b'B']], dtype=object))\n",
      "(array([[3, 3],\n",
      "       [3, 2]]), array([[b'A'],\n",
      "       [b'B']], dtype=object))\n"
     ]
    }
   ],
   "source": [
    "# 二位数组，拆除第一维\n",
    "dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
    "print(list(dataset.as_numpy_iterator()))\n",
    "# 对于元组来说，拆除的是元组内部的每一项的维度，最后再次合成元组，要把元组中的数据理解成一组数据\n",
    "dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
    "print(list(dataset.as_numpy_iterator()))\n",
    "# 拆除第一维，就是拆外面的数组\n",
    "dataset = tf.data.Dataset.from_tensor_slices([(1, 2), (3, 4), (5, 6)])\n",
    "print(list(dataset.as_numpy_iterator()))\n",
    "# 参数是dict，拆除dict的value的维度\n",
    "dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
    "print(list(dataset.as_numpy_iterator()))\n",
    "# dataset = tf.data.Dataset.from_tensor_slices({\"a\": (1, 2), \"b\": (3, 4)}) 这个会报错，说明拆不了元组\n",
    "# 参数是元组，拆里面每一项，每一项是dict，拆dict的value， ({a:1, b:3},{c:5}) , ({a:2, b:4},{c:6})\n",
    "dataset = tf.data.Dataset.from_tensor_slices(({\"a\": [1, 2], \"b\": [3, 4]}, {\"c\": [5, 6]}))\n",
    "print(list(dataset.as_numpy_iterator()))\n",
    "# 太离谱了，这特么也可以 ({'a': {'aa': 1}, 'b': {'bb': 3}}, {'c': {'cc': 5}}), ({'a': {'aa': 2}, 'b': {'bb': 4}}, {'c': {'cc': 6}})\n",
    "dataset = tf.data.Dataset.from_tensor_slices(({\"a\": {\"aa\": [1, 2]}, \"b\": {\"bb\": [3, 4]}}, {\"c\": {\"cc\": [5, 6]}}))\n",
    "print(list(dataset.as_numpy_iterator()))\n",
    "\n",
    "# Two tensors can be combined into one Dataset object.\n",
    "features = tf.constant([[1, 3], [2, 1], [3, 3]])  # ==> 3x2 tensor\n",
    "labels = tf.constant(['A', 'B', 'A'])  # ==> 3x1 tensor\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "# Both the features and the labels tensors can be converted\n",
    "# to a Dataset object separately and combined after.\n",
    "features_dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "labels_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "dataset = tf.data.Dataset.zip((features_dataset, labels_dataset))\n",
    "# A batched feature and label set can be converted to a Dataset\n",
    "# in similar fashion.\n",
    "batched_features = tf.constant([[[1, 3], [2, 3]],\n",
    "                                [[2, 1], [1, 2]],\n",
    "                                [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
    "batched_labels = tf.constant([['A', 'A'],\n",
    "                              ['B', 'B'],\n",
    "                              ['A', 'B']], shape=(3, 2, 1))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((batched_features, batched_labels))\n",
    "for element in dataset.as_numpy_iterator():\n",
    "    print(element)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T23:39:33.828552400Z",
     "start_time": "2024-05-07T23:39:33.795686100Z"
    }
   },
   "id": "5be54ca97109353b",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 基本机制\n",
    "tf.data API 引入了一个 tf.data.Dataset 抽象，它表示一个元素序列，其中每个元素都由一个或多个组件组成。例如，在一个图像流水线中，一个元素可能是一个训练样本，有一对表示图像及其标签的张量组件。\n",
    "听起来比较像 'List<Object>'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c130de9bb636ff52"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.int32>\n",
      "TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "8\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "3\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "0\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0])\n",
    "print(dataset)\n",
    "print(dataset.element_spec)\n",
    "\n",
    "for elem in dataset:\n",
    "    print(elem)\n",
    "    print(elem.numpy())\n",
    "print(\"--------------------------------------------------\")\n",
    "## reduce是根据多个Tensor最后生成一个Tensor\n",
    "print(dataset.reduce(0, lambda state, value: state + value))\n",
    "print(dataset.reduce(0, lambda state, value: state + value).numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T23:43:18.884762900Z",
     "start_time": "2024-05-07T23:43:18.834300200Z"
    }
   },
   "id": "691e8df5ffdc1c59",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.0453 0.405  0.2163 0.2185 0.6849 0.9378 0.7461 0.0604 0.3186 0.2357]\n",
      " [0.0149 0.329  0.4757 0.9239 0.9556 0.5419 0.1715 0.3097 0.9043 0.2356]\n",
      " [0.3267 0.0428 0.2049 0.4435 0.4263 0.6065 0.9213 0.9657 0.8955 0.9726]\n",
      " [0.1252 0.403  0.3521 0.8339 0.1415 0.7611 0.7627 0.8215 0.7089 0.2036]], shape=(4, 10), dtype=float32)\n",
      "<TensorSliceDataset shapes: (10,), types: tf.float32>\n",
      "TensorSpec(shape=(10,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "# random.uniform是产生一个4 * 10的随机数的Tensor\n",
    "print(tf.random.uniform([4, 10]))\n",
    "# 切片第一维，结果是一个，一堆 10维的向量，的数据集\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4, 10]))\n",
    "print(dataset1) # dateSet\n",
    "print(dataset1.element_spec)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T23:52:34.432049300Z",
     "start_time": "2024-05-07T23:52:34.421705400Z"
    }
   },
   "id": "c99b1b03bea8dd71",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((), (100,)), types: (tf.float32, tf.int32)>\n",
      "(TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(100,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "# 这里展现的是，‘对于dateset而言，每个元素都是由多个或者一个组件组成'，这句话的含义，这里一组就是一整个元组，里面一个数字，一个100维向量\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
    "   (tf.random.uniform([4]),\n",
    "    tf.random.uniform([4, 100], maxval=100, dtype=tf.int32)))\n",
    "print(dataset2)\n",
    "print(dataset2.element_spec)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T00:15:05.829372800Z",
     "start_time": "2024-05-08T00:15:05.815906200Z"
    }
   },
   "id": "da06692f118dbf9d",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### tf.data.Dataset.zip()讲解"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35bcfdb31f9c9b4b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RangeDataset shapes: (), types: tf.int64>\n",
      "<ZipDataset shapes: ((), ()), types: (tf.int64, tf.int64)>\n",
      "------------------------------------------------------\n",
      "[(1, 4), (2, 5), (3, 6)]\n",
      "------------------------------------------------------\n",
      "[(4, 1), (5, 2), (6, 3)]\n",
      "------------------------------------------------------\n",
      "<BatchDataset shapes: (None,), types: tf.int64>\n",
      "TensorSpec(shape=(None,), dtype=tf.int64, name=None)\n",
      "[array([7, 8], dtype=int64), array([ 9, 10], dtype=int64), array([11, 12], dtype=int64)]\n",
      "----------------------------------------------------\n",
      "(1, 4, array([7, 8], dtype=int64))\n",
      "(2, 5, array([ 9, 10], dtype=int64))\n",
      "(3, 6, array([11, 12], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# The nested structure of the `datasets` argument determines the\n",
    "# structure of elements in the resulting dataset.\n",
    "a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
    "b = tf.data.Dataset.range(4, 7)  # ==> [ 4, 5, 6 ]\n",
    "print(a)  # DateSet\n",
    "ds = tf.data.Dataset.zip((a, b))\n",
    "print(ds) # dateSet\n",
    "print(\"------------------------------------------------------\")\n",
    "print(list(ds.as_numpy_iterator()))\n",
    "print(\"------------------------------------------------------\")\n",
    "ds = tf.data.Dataset.zip((b, a))\n",
    "print(list(ds.as_numpy_iterator()))\n",
    "print(\"------------------------------------------------------\")\n",
    "\n",
    "# The `datasets` argument may contain an arbitrary number of datasets.\n",
    "c = tf.data.Dataset.range(7, 13).batch(2)  # ==> [ [7, 8],\n",
    "                                           #       [9, 10],\n",
    "                                           #       [11, 12] ]\n",
    "print(c)\n",
    "print(c.element_spec)\n",
    "print(list(c.as_numpy_iterator()))\n",
    "print(\"----------------------------------------------------\")\n",
    "ds = tf.data.Dataset.zip((a, b, c))\n",
    "for element in ds.as_numpy_iterator():\n",
    "  print(element)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T00:25:03.572126800Z",
     "start_time": "2024-05-08T00:25:03.551542300Z"
    }
   },
   "id": "c41b0703ca4a19c3",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "abc77abaa2952d62"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
